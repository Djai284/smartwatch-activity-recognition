{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sig_array</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.1832595, -0.2076941, -0.53145254, 9.77168...</td>\n",
       "      <td>squats</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1.502728, -1.7263045, -1.4062113, 0.86939216...</td>\n",
       "      <td>squats</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.21502449, -1.5980228, -1.4941758, 6.47373...</td>\n",
       "      <td>non-e</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[0.6059781, 0.07819072, -0.53633946, 7.046148...</td>\n",
       "      <td>non-e</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[0.09896013, -0.2724458, 0.53145254, 1.087338...</td>\n",
       "      <td>non-e</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          sig_array activity_name  \\\n",
       "0   0  [[-0.1832595, -0.2076941, -0.53145254, 9.77168...        squats   \n",
       "1   1  [[1.502728, -1.7263045, -1.4062113, 0.86939216...        squats   \n",
       "2   2  [[-0.21502449, -1.5980228, -1.4941758, 6.47373...         non-e   \n",
       "3   3  [[0.6059781, 0.07819072, -0.53633946, 7.046148...         non-e   \n",
       "4   4  [[0.09896013, -0.2724458, 0.53145254, 1.087338...         non-e   \n",
       "\n",
       "  subject_id dataset  \n",
       "0          0   mmfit  \n",
       "1          0   mmfit  \n",
       "2          0   mmfit  \n",
       "3          0   mmfit  \n",
       "4          0   mmfit  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/model_data_window_500_space_50.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 unique activities in the dataset\n"
     ]
    }
   ],
   "source": [
    "# limit to labels with enough examples\n",
    "\n",
    "counts = df['activity_name'].value_counts()\n",
    "valid_activities = [activity for activity in counts.index.tolist() if counts[activity] >=500]\n",
    "df = df[df['activity_name'].isin(valid_activities)]\n",
    "\n",
    "print(f\"There are {len(df['activity_name'].unique())} unique activities in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_fix_dict = {'non-e' : 'rest',\n",
    "                 'nonexercise': 'rest',\n",
    "                 'staticstretch(atyourownpace)': 'staticstretch',\n",
    "                 'two-armdumbbellcurl(botharms,notalternating)': 'bicepcurls'}\n",
    "\n",
    "\n",
    "df['activity_name'] = df['activity_name'].apply(lambda x: name_fix_dict[x] if x in name_fix_dict.keys() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sizes of the Train, Test, and Val Sets are:\n",
      "Train Size: 116440\n",
      "Test Size: 32224\n",
      "Val Size: 10787\n"
     ]
    }
   ],
   "source": [
    "# Create test train val split on the user level\n",
    "\n",
    "# split test/train\n",
    "train_users, test_users = train_test_split(df['subject_id'].unique(), train_size=.8, random_state=42)\n",
    "\n",
    "train_data = df[df['subject_id'].isin(train_users)]\n",
    "test_data = df[df['subject_id'].isin(test_users)]\n",
    "\n",
    "# split train/val\n",
    "train_users, val_users = train_test_split(train_data['subject_id'].unique(), train_size=.9, random_state=42)\n",
    "\n",
    "val_data = train_data[train_data['subject_id'].isin(val_users)]\n",
    "train_data = train_data[train_data['subject_id'].isin(train_users)]\n",
    "\n",
    "print(\"The Sizes of the Train, Test, and Val Sets are:\")\n",
    "print(f\"Train Size: {len(train_data)}\")\n",
    "print(f\"Test Size: {len(test_data)}\")\n",
    "print(f\"Val Size: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate X and Y components of data\n",
    "\n",
    "X_train = np.array(train_data['sig_array'])\n",
    "X_test = np.array(test_data['sig_array'])\n",
    "X_Val = np.array(val_data['sig_array'])\n",
    "\n",
    "y_train = np.array(train_data['activity_name'])\n",
    "y_test = np.array(test_data['activity_name'])\n",
    "y_val = np.array(val_data['activity_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data in right format\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "\n",
    "X_train = np.stack(X_train).astype(np.float32)\n",
    "X_test = np.stack(X_test).astype(np.float32)\n",
    "X_Val = np.stack(X_Val).astype(np.float32)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "X_Val_tensor = torch.tensor(X_Val, dtype=torch.float32)\n",
    "\n",
    "# Convert y arrays to tensors\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).permute(0, 2, 1)  # Convert to tensor and swap axes\n",
    "        self.y = torch.tensor(y, dtype=torch.long)  # Ensure labels are integers for classification\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create Dataset Objects\n",
    "train_dataset = IMUDataset(X_train, y_train_encoded)\n",
    "val_dataset = IMUDataset(X_Val, y_val_encoded)\n",
    "test_dataset = IMUDataset(X_test, y_test_encoded)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.2645, Val Accuracy: 64.95%, Train Accuracy 74.53%\n",
      "Epoch [2/20], Loss: 0.7381, Val Accuracy: 74.24%, Train Accuracy 81.42%\n",
      "Epoch [3/20], Loss: 0.6049, Val Accuracy: 74.23%, Train Accuracy 82.60%\n",
      "Epoch [4/20], Loss: 0.5331, Val Accuracy: 75.45%, Train Accuracy 84.93%\n",
      "Epoch [5/20], Loss: 0.4734, Val Accuracy: 72.63%, Train Accuracy 86.59%\n",
      "Epoch [6/20], Loss: 0.4468, Val Accuracy: 77.61%, Train Accuracy 88.60%\n",
      "Epoch [7/20], Loss: 0.4164, Val Accuracy: 75.59%, Train Accuracy 89.63%\n",
      "Epoch [8/20], Loss: 0.3875, Val Accuracy: 76.53%, Train Accuracy 90.39%\n",
      "Epoch [9/20], Loss: 0.3803, Val Accuracy: 72.47%, Train Accuracy 89.71%\n",
      "Epoch [10/20], Loss: 0.3541, Val Accuracy: 70.97%, Train Accuracy 90.71%\n",
      "Epoch [11/20], Loss: 0.3526, Val Accuracy: 77.88%, Train Accuracy 91.16%\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Model setup\n",
    "num_classes = len(np.unique(y_train_encoded))\n",
    "window_length = 300  \n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = IMUCNN(num_classes=num_classes, window_length=window_length).to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    #  Compute validation accuracy\n",
    "    val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "    train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Train Accuracy {train_accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get class with highest probability\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.66      0.59       344\n",
      "           1       0.84      0.90      0.87       698\n",
      "           2       0.62      0.42      0.50       317\n",
      "           3       0.96      0.89      0.93       731\n",
      "           4       0.57      0.73      0.64       377\n",
      "           5       0.67      0.34      0.45       226\n",
      "           6       0.91      0.94      0.93       556\n",
      "           7       0.96      0.92      0.94       762\n",
      "           8       0.95      0.94      0.94      4514\n",
      "           9       0.64      0.56      0.59       151\n",
      "          10       0.89      0.92      0.90       171\n",
      "          11       0.29      0.54      0.38       525\n",
      "          12       0.89      0.91      0.90       421\n",
      "          13       0.31      0.28      0.29       823\n",
      "          14       0.88      0.95      0.91       494\n",
      "          15       0.88      0.67      0.76       157\n",
      "          16       0.86      0.73      0.79       257\n",
      "          17       0.73      0.92      0.81       540\n",
      "          18       0.93      0.65      0.76       502\n",
      "          19       0.49      0.96      0.65       175\n",
      "          20       0.93      0.97      0.95       116\n",
      "          21       0.48      0.29      0.36       198\n",
      "          22       0.73      0.63      0.68       749\n",
      "          23       0.25      0.17      0.20        82\n",
      "          24       0.25      0.23      0.24       257\n",
      "          25       0.77      0.61      0.68       311\n",
      "          26       0.71      0.79      0.75       110\n",
      "          27       0.82      0.98      0.89       327\n",
      "          28       0.85      0.77      0.81       973\n",
      "          29       0.00      0.00      0.00       225\n",
      "          30       0.83      0.83      0.83      6563\n",
      "          31       0.83      0.45      0.58       480\n",
      "          32       0.60      0.85      0.70       296\n",
      "          33       0.22      0.27      0.24       240\n",
      "          34       0.37      0.34      0.36       189\n",
      "          35       0.79      0.64      0.71       106\n",
      "          36       0.42      0.58      0.49       101\n",
      "          37       0.44      0.46      0.45       229\n",
      "          38       0.59      0.75      0.66       397\n",
      "          39       0.65      0.58      0.61      1837\n",
      "          40       0.53      0.60      0.56      2265\n",
      "          41       0.94      0.77      0.85       118\n",
      "          42       0.51      0.58      0.54       634\n",
      "          43       0.33      0.42      0.37       249\n",
      "          44       0.94      0.72      0.82      1805\n",
      "          45       0.36      0.65      0.46        86\n",
      "          46       0.87      1.00      0.93       540\n",
      "\n",
      "    accuracy                           0.74     32224\n",
      "   macro avg       0.65      0.65      0.64     32224\n",
      "weighted avg       0.75      0.74      0.74     32224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "y_pred, y_true = predict(model, test_loader, device)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
