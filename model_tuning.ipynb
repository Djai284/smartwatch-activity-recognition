{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/model_data_window_300_space_50.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_fix_dict = {'non-e' : 'rest',\n",
    "                 'nonexercise': 'rest',\n",
    "                 'staticstretch(atyourownpace)': 'staticstretch',\n",
    "                 'two-armdumbbellcurl(botharms,notalternating)': 'bicepcurls',\n",
    "                 'wallballs': 'wallball',\n",
    "                 'dumbbell_shoulder_press': 'dumbbellshoulderpress',\n",
    "                 'lateral_shoulder_raises': 'lateralshoulderraises',\n",
    "                 'sit-up(handspositionedbehindhead)': 'situps'}\n",
    "\n",
    "\n",
    "df['activity_name'] = df['activity_name'].apply(lambda x: name_fix_dict[x] if x in name_fix_dict.keys() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['squats', 'rest', 'pushups', 'dumbbellshoulderpress', 'lunges',\n",
       "       'dumbbell_rows', 'situps', 'tricep_extensions', 'bicep_curls',\n",
       "       'lateralshoulderraises', 'jumping_jacks', 'kbpress', 'boxjumps',\n",
       "       'deadlifts', 'crunches', 'kbsquatpress', 'null', 'wallball',\n",
       "       'burpees', 'pullups', 'dip', 'bicepscurl(band)',\n",
       "       'ellipticalmachine', 'staticstretch', 'sideplankleftside',\n",
       "       'burpee', 'bicepcurls', 'tricepextensions',\n",
       "       'fastalternatingpunches', 'dynamicstretch(atyourownpace)', 'walk',\n",
       "       'plank', 'v-up', 'dumbbellrows', 'deviceontable',\n",
       "       'kettlebellswing', 'russiantwist', 'crunch', 'seatedbackfly',\n",
       "       'butterflysit-up', 'jumprope', 'sideplankrightside', 'note',\n",
       "       'taprightdevice', 'repetitivestretching', 'jumpingjacks',\n",
       "       'powerboatpose', 'tapleftdevice', 'unlistedexercise',\n",
       "       'armbandadjustment', 'running(treadmill)', 'medicineballslam',\n",
       "       'overheadtricepsextension(labelspansbotharms)', 'bandpull-downrow',\n",
       "       'chestpress(rack)', 'rowingmachine', 'lawnmower(rightarm)',\n",
       "       'lawnmower(leftarm)', 'alternatingdumbbellcurl'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activity_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['har_data'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['activity_name']=='null']['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34 unique activities in the dataset\n"
     ]
    }
   ],
   "source": [
    "# limit to labels with enough examples\n",
    "\n",
    "counts = df['activity_name'].value_counts()\n",
    "valid_activities = [activity for activity in counts.index.tolist() if counts[activity] >=1000]\n",
    "df = df[df['activity_name'].isin(valid_activities)]\n",
    "\n",
    "print(f\"There are {len(df['activity_name'].unique())} unique activities in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sizes of the Train, Test, and Val Sets are:\n",
      "Train Size: 111373\n",
      "Test Size: 30961\n",
      "Val Size: 10312\n"
     ]
    }
   ],
   "source": [
    "# Create test train val split on the user level\n",
    "\n",
    "# split test/train\n",
    "train_users, test_users = train_test_split(df['subject_id'].unique(), train_size=.8, random_state=42)\n",
    "\n",
    "train_data = df[df['subject_id'].isin(train_users)]\n",
    "test_data = df[df['subject_id'].isin(test_users)]\n",
    "\n",
    "# split train/val\n",
    "train_users, val_users = train_test_split(train_data['subject_id'].unique(), train_size=.9, random_state=42)\n",
    "\n",
    "val_data = train_data[train_data['subject_id'].isin(val_users)]\n",
    "train_data = train_data[train_data['subject_id'].isin(train_users)]\n",
    "\n",
    "print(\"The Sizes of the Train, Test, and Val Sets are:\")\n",
    "print(f\"Train Size: {len(train_data)}\")\n",
    "print(f\"Test Size: {len(test_data)}\")\n",
    "print(f\"Val Size: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate X and Y components of data\n",
    "\n",
    "X_train = np.array(train_data['sig_array'])\n",
    "X_test = np.array(test_data['sig_array'])\n",
    "X_Val = np.array(val_data['sig_array'])\n",
    "\n",
    "y_train = np.array(train_data['activity_name'])\n",
    "y_test = np.array(test_data['activity_name'])\n",
    "y_val = np.array(val_data['activity_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data in right format\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "\n",
    "X_train = np.stack(X_train).astype(np.float32)\n",
    "X_test = np.stack(X_test).astype(np.float32)\n",
    "X_Val = np.stack(X_Val).astype(np.float32)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "X_Val_tensor = torch.tensor(X_Val, dtype=torch.float32)\n",
    "\n",
    "# Convert y arrays to tensors\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).permute(0, 2, 1)  # Convert to tensor and swap axes\n",
    "        self.y = torch.tensor(y, dtype=torch.long)  # Ensure labels are integers for classification\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create Dataset Objects\n",
    "train_dataset = IMUDataset(X_train, y_train_encoded)\n",
    "val_dataset = IMUDataset(X_Val, y_val_encoded)\n",
    "test_dataset = IMUDataset(X_test, y_test_encoded)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/jacobgottesman/Public/DS 4440/smartwatch-activity-recognition/model.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import model\n",
    "importlib.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-18 17:34:09,120] A new study created in memory with name: cnn_optimization_20250218_173409\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8de71ce62a45fd869e3f67e3bd4d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "[W 2025-02-18 17:34:11,230] Trial 0 failed with parameters: {'conv_layers': 3, 'kernel_size': 15, 'initial_filters': 192, 'dropout_rate': 0.559195090518222, 'learning_rate': 2.9380279387035334e-05, 'weight_decay': 2.9375384576328313e-06, 'n_hidden_layers': 1, 'hidden_layer_0': 448} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/Users/jacobgottesman/Public/DS 4440/smartwatch-activity-recognition/model.py\", line 769, in <lambda>\n",
      "    lambda trial: objective(\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/Users/jacobgottesman/Public/DS 4440/smartwatch-activity-recognition/model.py\", line 722, in objective\n",
      "    model, history = train_model_with_advanced_logging(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jacobgottesman/Public/DS 4440/smartwatch-activity-recognition/model.py\", line 590, in train_model_with_advanced_logging\n",
      "    writer.add_scalar('Gradient_Norm/train', grad_norm, epoch)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py\", line 378, in add_scalar\n",
      "    summary = scalar(\n",
      "              ^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py\", line 371, in scalar\n",
      "    tensor = make_np(tensor).squeeze()\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_convert_np.py\", line 24, in make_np\n",
      "    return _prepare_pytorch(x)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_convert_np.py\", line 33, in _prepare_pytorch\n",
      "    x = x.detach().cpu().numpy()\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-18 17:34:11,233] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run hyperparameter tuning\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m study \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrun_hyperparameter_tuning(\n\u001b[1;32m     10\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[1;32m     11\u001b[0m     val_loader\u001b[38;5;241m=\u001b[39mval_loader,\n\u001b[1;32m     12\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     13\u001b[0m     input_channels\u001b[38;5;241m=\u001b[39minput_channels,\n\u001b[1;32m     14\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[1;32m     15\u001b[0m     window_length\u001b[38;5;241m=\u001b[39mwindow_length,\n\u001b[1;32m     16\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     17\u001b[0m     class_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(label_encoder\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m     18\u001b[0m )\n",
      "File \u001b[0;32m~/Public/DS 4440/smartwatch-activity-recognition/model.py:768\u001b[0m, in \u001b[0;36mrun_hyperparameter_tuning\u001b[0;34m(train_loader, val_loader, device, input_channels, num_classes, window_length, n_trials, study_name, class_names)\u001b[0m\n\u001b[1;32m    760\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    761\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name,\n\u001b[1;32m    762\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    763\u001b[0m     sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[1;32m    764\u001b[0m     pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner(n_startup_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    765\u001b[0m )\n\u001b[1;32m    767\u001b[0m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[0;32m--> 768\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(\n\u001b[1;32m    770\u001b[0m         trial, \n\u001b[1;32m    771\u001b[0m         train_loader, \n\u001b[1;32m    772\u001b[0m         val_loader, \n\u001b[1;32m    773\u001b[0m         device, \n\u001b[1;32m    774\u001b[0m         input_channels, \n\u001b[1;32m    775\u001b[0m         num_classes, \n\u001b[1;32m    776\u001b[0m         window_length,\n\u001b[1;32m    777\u001b[0m         class_names\n\u001b[1;32m    778\u001b[0m     ),\n\u001b[1;32m    779\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    780\u001b[0m     show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    781\u001b[0m )\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     _optimize(\n\u001b[1;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    485\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[1;32m     64\u001b[0m             study,\n\u001b[1;32m     65\u001b[0m             func,\n\u001b[1;32m     66\u001b[0m             n_trials,\n\u001b[1;32m     67\u001b[0m             timeout,\n\u001b[1;32m     68\u001b[0m             catch,\n\u001b[1;32m     69\u001b[0m             callbacks,\n\u001b[1;32m     70\u001b[0m             gc_after_trial,\n\u001b[1;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/Public/DS 4440/smartwatch-activity-recognition/model.py:769\u001b[0m, in \u001b[0;36mrun_hyperparameter_tuning.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    760\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    761\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name,\n\u001b[1;32m    762\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    763\u001b[0m     sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[1;32m    764\u001b[0m     pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner(n_startup_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    765\u001b[0m )\n\u001b[1;32m    767\u001b[0m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[1;32m    768\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(\n\u001b[1;32m    770\u001b[0m         trial, \n\u001b[1;32m    771\u001b[0m         train_loader, \n\u001b[1;32m    772\u001b[0m         val_loader, \n\u001b[1;32m    773\u001b[0m         device, \n\u001b[1;32m    774\u001b[0m         input_channels, \n\u001b[1;32m    775\u001b[0m         num_classes, \n\u001b[1;32m    776\u001b[0m         window_length,\n\u001b[1;32m    777\u001b[0m         class_names\n\u001b[1;32m    778\u001b[0m     ),\n\u001b[1;32m    779\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    780\u001b[0m     show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    781\u001b[0m )\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m~/Public/DS 4440/smartwatch-activity-recognition/model.py:722\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, train_loader, val_loader, device, input_channels, num_classes, window_length, class_names)\u001b[0m\n\u001b[1;32m    718\u001b[0m trial_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrial_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_conv\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv_layers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ker\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m model, history \u001b[38;5;241m=\u001b[39m train_model_with_advanced_logging(\n\u001b[1;32m    723\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    724\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[1;32m    725\u001b[0m     val_loader\u001b[38;5;241m=\u001b[39mval_loader,\n\u001b[1;32m    726\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    727\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mtrial_name,\n\u001b[1;32m    728\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    729\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    730\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \n\u001b[1;32m    731\u001b[0m     early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    732\u001b[0m     class_names\u001b[38;5;241m=\u001b[39m class_names\n\u001b[1;32m    733\u001b[0m )\n\u001b[1;32m    735\u001b[0m \u001b[38;5;66;03m# Get best validation metrics\u001b[39;00m\n\u001b[1;32m    736\u001b[0m best_val_f1_macro \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Public/DS 4440/smartwatch-activity-recognition/model.py:590\u001b[0m, in \u001b[0;36mtrain_model_with_advanced_logging\u001b[0;34m(model, train_loader, val_loader, device, model_name, num_epochs, learning_rate, weight_decay, base_log_dir, early_stopping_patience, augmenter, class_names)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;66;03m# Log gradient norms\u001b[39;00m\n\u001b[1;32m    589\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 590\u001b[0m         writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradient_Norm/train\u001b[39m\u001b[38;5;124m'\u001b[39m, grad_norm, epoch)\n\u001b[1;32m    591\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    593\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m X_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:378\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add scalar data to summary.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 378\u001b[0m summary \u001b[38;5;241m=\u001b[39m scalar(\n\u001b[1;32m    379\u001b[0m     tag, scalar_value, new_style\u001b[38;5;241m=\u001b[39mnew_style, double_precision\u001b[38;5;241m=\u001b[39mdouble_precision\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(summary, global_step, walltime)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py:371\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, tensor, collections, new_style, double_precision)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscalar\u001b[39m(name, tensor, collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, new_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, double_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Output a `Summary` protocol buffer containing a single scalar value.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m    The generated Summary has a Tensor.proto containing the input Tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m      ValueError: If tensor has the wrong shape or type.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m make_np(tensor)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    373\u001b[0m         tensor\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    374\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor should contain one element (0 dimensions). Was given size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# python float is double precision in numpy\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_convert_np.py:24\u001b[0m, in \u001b[0;36mmake_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([x])\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _prepare_pytorch(x)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but numpy array or torch tensor are expected.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_convert_np.py:33\u001b[0m, in \u001b[0;36m_prepare_pytorch\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16:\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[0;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "input_channels = 6  # Number of input channels in your data\n",
    "num_classes = 34     # Number of classes in your classification task\n",
    "window_length = 300 # Length of your input sequences\n",
    "# Set device to mps if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "study = model.run_hyperparameter_tuning(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    input_channels=input_channels,\n",
    "    num_classes=num_classes,\n",
    "    window_length=window_length,\n",
    "    n_trials=30,\n",
    "    class_names = list(label_encoder.classes_)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best trial:\n",
      "\n",
      "Best F1 Macro Score: 0.7746\n",
      "\n",
      "Best hyperparameters:\n",
      "  conv_layers: 3\n",
      "  kernel_size: 15\n",
      "  initial_filters: 192\n",
      "  dropout_rate: 0.559195090518222\n",
      "  learning_rate: 2.9380279387035334e-05\n",
      "  weight_decay: 2.9375384576328313e-06\n",
      "  n_hidden_layers: 1\n",
      "  hidden_layer_0: 448\n",
      "\n",
      "Best validation loss: 0.5193\n",
      "dict_keys(['conv_layers', 'kernel_size', 'initial_filters', 'dropout_rate', 'learning_rate', 'weight_decay', 'n_hidden_layers', 'hidden_layer_0'])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': 3, 'kernel_size': 15, 'initial_filters': 192, 'dropout_rate': 0.559195090518222, 'hidden_layers': [448]}\n"
     ]
    }
   ],
   "source": [
    "# Analyze results\n",
    "best_params = analyze_study_results(study)\n",
    "\n",
    "\n",
    "non_model_param_keys = ['learning_rate', 'weight_decay', 'n_hidden_layers'] + [f'hidden_layer_{i}' for i in range(best_params['n_hidden_layers'])]\n",
    "model_params = {key:val for key, val in best_params.items() if key not in non_model_param_keys}\n",
    "model_params['hidden_layers'] = [best_params[f'hidden_layer_{i}'] for i in range(best_params['n_hidden_layers'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning:\n",
      "\n",
      "The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m final_model \u001b[38;5;241m=\u001b[39m FlexibleCNN(\n\u001b[1;32m      3\u001b[0m     input_channels\u001b[38;5;241m=\u001b[39minput_channels,\n\u001b[1;32m      4\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[1;32m      5\u001b[0m     window_length\u001b[38;5;241m=\u001b[39mwindow_length,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_params\n\u001b[1;32m      7\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the final model with full epochs\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m final_model, history \u001b[38;5;241m=\u001b[39m train_model_with_advanced_logging(\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39mfinal_model,\n\u001b[1;32m     12\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[1;32m     13\u001b[0m     val_loader\u001b[38;5;241m=\u001b[39mval_loader,\n\u001b[1;32m     14\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     15\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     17\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m ,\n\u001b[1;32m     19\u001b[0m     class_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(label_encoder\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluate on test set\u001b[39;00m\n\u001b[1;32m     23\u001b[0m final_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Public/DS 4440/smartwatch-activity-recognition/model.py:581\u001b[0m, in \u001b[0;36mtrain_model_with_advanced_logging\u001b[0;34m(model, train_loader, val_loader, device, model_name, num_epochs, learning_rate, weight_decay, base_log_dir, early_stopping_patience, augmenter, class_names)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:378\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add scalar data to summary.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 378\u001b[0m summary \u001b[38;5;241m=\u001b[39m scalar(\n\u001b[1;32m    379\u001b[0m     tag, scalar_value, new_style\u001b[38;5;241m=\u001b[39mnew_style, double_precision\u001b[38;5;241m=\u001b[39mdouble_precision\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(summary, global_step, walltime)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py:371\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, tensor, collections, new_style, double_precision)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscalar\u001b[39m(name, tensor, collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, new_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, double_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Output a `Summary` protocol buffer containing a single scalar value.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m    The generated Summary has a Tensor.proto containing the input Tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m      ValueError: If tensor has the wrong shape or type.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m make_np(tensor)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    373\u001b[0m         tensor\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    374\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor should contain one element (0 dimensions). Was given size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# python float is double precision in numpy\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_convert_np.py:24\u001b[0m, in \u001b[0;36mmake_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([x])\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _prepare_pytorch(x)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but numpy array or torch tensor are expected.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_convert_np.py:33\u001b[0m, in \u001b[0;36m_prepare_pytorch\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16:\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[0;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model = FlexibleCNN(\n",
    "    input_channels=input_channels,\n",
    "    num_classes=num_classes,\n",
    "    window_length=window_length,\n",
    "    **model_params\n",
    ").to(device)\n",
    "\n",
    "# Train the final model with full epochs\n",
    "final_model, history = train_model_with_advanced_logging(\n",
    "    model=final_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    model_name=\"final_model\",\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay'],\n",
    "    num_epochs=100 ,\n",
    "    class_names = list(label_encoder.classes_)\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "final_model.eval()\n",
    "test_predictions = []\n",
    "test_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = final_model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_predictions.extend(predicted.cpu().numpy())\n",
    "        test_true.extend(y_batch.numpy())\n",
    "\n",
    "# Calculate final test metrics\n",
    "test_accuracy = accuracy_score(test_true, test_predictions)\n",
    "test_f1_macro = f1_score(test_true, test_predictions, average='macro')\n",
    "test_f1_weighted = f1_score(test_true, test_predictions, average='weighted')\n",
    "\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Macro F1: {test_f1_macro:.4f}\")\n",
    "print(f\"Weighted F1: {test_f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
