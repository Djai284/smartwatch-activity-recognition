{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# # save_results.py\n",
    "# import json\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Create the results dictionary with values from the log\n",
    "# results = {\n",
    "#     'cv_results': [\n",
    "#         {\n",
    "#             'fold': 0,\n",
    "#             'best_val_loss': 0.0403,\n",
    "#             'final_val_acc': 98.84\n",
    "#         },\n",
    "#         {\n",
    "#             'fold': 1,\n",
    "#             'best_val_loss': 0.0426,\n",
    "#             'final_val_acc': 98.69\n",
    "#         },\n",
    "#         {\n",
    "#             'fold': 2,  # Early stopped\n",
    "#             'best_val_loss': 4.8652,\n",
    "#             'final_val_acc': 38.04\n",
    "#         },\n",
    "#         {\n",
    "#             'fold': 3,  # Early stopped\n",
    "#             'best_val_loss': 4.7516,\n",
    "#             'final_val_acc': 36.40\n",
    "#         },\n",
    "#         {\n",
    "#             'fold': 4,\n",
    "#             'best_val_loss': 0.0405,\n",
    "#             'final_val_acc': 98.80\n",
    "#         }\n",
    "#     ],\n",
    "#     'num_classes': 67,\n",
    "#     'window_length': 500,\n",
    "#     'best_fold': 0,  # Fold 1 had the best performance\n",
    "#     'best_val_loss': 0.0403,  # From fold 1\n",
    "#     'best_val_acc': 98.84  # From fold 1\n",
    "# }\n",
    "\n",
    "# # Create logs directory if it doesn't exist\n",
    "# log_dir = Path(\"logs\")\n",
    "# log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# # Save results\n",
    "# with open(log_dir / \"training_results.json\", 'w') as f:\n",
    "#     json.dump(results, f, indent=4)\n",
    "\n",
    "# print(\"Training results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading data...\n",
      "Number of classes: 67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from utils.config import Config\n",
    "from model import IMUCNN, TimeSeriesAugmentation\n",
    "from utils.data_processing import SignalPreprocessor, ExerciseDataset\n",
    "from utils.training import train_model_with_cv, optimize_for_mobile\n",
    "\n",
    "# Load configuration\n",
    "config = Config()\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "data = pd.read_pickle(config.data_dir / 'model_data_window_500_space_50.pkl')\n",
    "\n",
    "# Set number of classes based on data\n",
    "config.num_classes = len(data['activity_name'].unique())\n",
    "print(f\"Number of classes: {config.num_classes}\")\n",
    "\n",
    "# Add sampling rate information to dataset\n",
    "data['sampling_rate'] = data['dataset'].map({\n",
    "    'mmfit': 100,\n",
    "    'har_data': 100,\n",
    "    'reco': 50\n",
    "})\n",
    "\n",
    "# Train with cross-validation\n",
    "# print(\"Starting cross-validation training...\")\n",
    "# cv_results = train_model_with_cv(IMUCNN, data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sig_array</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>sampling_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.1832595, -0.2076941, -0.53145254, 9.77168...</td>\n",
       "      <td>squats</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1.502728, -1.7263045, -1.4062113, 0.86939216...</td>\n",
       "      <td>squats</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.21502449, -1.5980228, -1.4941758, 6.47373...</td>\n",
       "      <td>non-e</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[0.6059781, 0.07819072, -0.53633946, 7.046148...</td>\n",
       "      <td>non-e</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[0.09896013, -0.2724458, 0.53145254, 1.087338...</td>\n",
       "      <td>non-e</td>\n",
       "      <td>0</td>\n",
       "      <td>mmfit</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151782</th>\n",
       "      <td>151782</td>\n",
       "      <td>[[0.6453633617195623, -3.3918659447031194, 0.6...</td>\n",
       "      <td>deviceontable</td>\n",
       "      <td>reco_10006</td>\n",
       "      <td>reco</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151783</th>\n",
       "      <td>151783</td>\n",
       "      <td>[[0.5943834536410079, -3.3774912748098864, 0.6...</td>\n",
       "      <td>deviceontable</td>\n",
       "      <td>reco_10006</td>\n",
       "      <td>reco</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151784</th>\n",
       "      <td>151784</td>\n",
       "      <td>[[0.5968571751596301, -3.3746797423858386, 0.6...</td>\n",
       "      <td>deviceontable</td>\n",
       "      <td>reco_10006</td>\n",
       "      <td>reco</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151785</th>\n",
       "      <td>151785</td>\n",
       "      <td>[[0.6648895340216258, -3.32562119567251, 0.689...</td>\n",
       "      <td>deviceontable</td>\n",
       "      <td>reco_10006</td>\n",
       "      <td>reco</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151786</th>\n",
       "      <td>151786</td>\n",
       "      <td>[[0.6175027016798849, -3.38652396287669, 0.653...</td>\n",
       "      <td>deviceontable</td>\n",
       "      <td>reco_10006</td>\n",
       "      <td>reco</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151787 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                          sig_array  \\\n",
       "0            0  [[-0.1832595, -0.2076941, -0.53145254, 9.77168...   \n",
       "1            1  [[1.502728, -1.7263045, -1.4062113, 0.86939216...   \n",
       "2            2  [[-0.21502449, -1.5980228, -1.4941758, 6.47373...   \n",
       "3            3  [[0.6059781, 0.07819072, -0.53633946, 7.046148...   \n",
       "4            4  [[0.09896013, -0.2724458, 0.53145254, 1.087338...   \n",
       "...        ...                                                ...   \n",
       "151782  151782  [[0.6453633617195623, -3.3918659447031194, 0.6...   \n",
       "151783  151783  [[0.5943834536410079, -3.3774912748098864, 0.6...   \n",
       "151784  151784  [[0.5968571751596301, -3.3746797423858386, 0.6...   \n",
       "151785  151785  [[0.6648895340216258, -3.32562119567251, 0.689...   \n",
       "151786  151786  [[0.6175027016798849, -3.38652396287669, 0.653...   \n",
       "\n",
       "        activity_name  subject_id dataset  sampling_rate  \n",
       "0              squats           0   mmfit            100  \n",
       "1              squats           0   mmfit            100  \n",
       "2               non-e           0   mmfit            100  \n",
       "3               non-e           0   mmfit            100  \n",
       "4               non-e           0   mmfit            100  \n",
       "...               ...         ...     ...            ...  \n",
       "151782  deviceontable  reco_10006    reco             50  \n",
       "151783  deviceontable  reco_10006    reco             50  \n",
       "151784  deviceontable  reco_10006    reco             50  \n",
       "151785  deviceontable  reco_10006    reco             50  \n",
       "151786  deviceontable  reco_10006    reco             50  \n",
       "\n",
       "[151787 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optimize_mobile.py\n",
    "# import torch\n",
    "# import json\n",
    "# from pathlib import Path\n",
    "# from model import IMUCNN\n",
    "\n",
    "# def optimize_for_mobile(model, config):\n",
    "#     \"\"\"Optimize model for mobile deployment using TorchScript only\"\"\"\n",
    "#     print(\"Optimizing model for mobile deployment...\")\n",
    "    \n",
    "#     # Move model to CPU and eval mode\n",
    "#     model = model.cpu()\n",
    "#     model.eval()\n",
    "    \n",
    "#     # Create example input\n",
    "#     example_input = torch.randn(\n",
    "#         1, 6, config['window_length'],\n",
    "#         device='cpu'\n",
    "#     )\n",
    "    \n",
    "#     # Export to TorchScript\n",
    "#     print(\"Tracing model...\")\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         # Trace the model\n",
    "#         traced_model = torch.jit.trace(model, example_input)\n",
    "        \n",
    "#         # Test the traced model\n",
    "#         print(\"Validating traced model...\")\n",
    "#         original_output = model(example_input)\n",
    "#         traced_output = traced_model(example_input)\n",
    "        \n",
    "#         if torch.allclose(original_output, traced_output):\n",
    "#             print(\"Traced model validated successfully!\")\n",
    "#         else:\n",
    "#             print(\"Warning: Traced model outputs differ from original model!\")\n",
    "    \n",
    "#     # Save optimized model\n",
    "#     output_path = Path(\"models\") / \"mobile_optimized_model.pt\"\n",
    "#     traced_model.save(str(output_path))\n",
    "#     print(f\"Saved optimized model to {output_path}\")\n",
    "    \n",
    "#     # Calculate and log model sizes\n",
    "#     model_path = Path(\"models\") / f\"best_model_fold_{config['best_fold']}.pt\"\n",
    "#     original_size = model_path.stat().st_size\n",
    "#     optimized_size = output_path.stat().st_size\n",
    "    \n",
    "#     print(f\"\\nModel size comparison:\")\n",
    "#     print(f\"Original model size: {original_size/1024:.2f} KB\")\n",
    "#     print(f\"Optimized model size: {optimized_size/1024:.2f} KB\")\n",
    "#     print(f\"Size reduction: {100*(1-optimized_size/original_size):.1f}%\")\n",
    "    \n",
    "#     return traced_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training results...\n",
      "Loaded results - Best fold: 0\n",
      "Best validation accuracy: 98.84%\n",
      "Loading model from models/best_model_fold_0.pt\n",
      "Optimizing model for mobile deployment...\n",
      "Tracing model...\n",
      "Validating traced model...\n",
      "Traced model validated successfully!\n",
      "Saved optimized model to models/mobile_optimized_model.pt\n",
      "\n",
      "Model size comparison:\n",
      "Original model size: 16548.56 KB\n",
      "Optimized model size: 16587.98 KB\n",
      "Size reduction: -0.2%\n",
      "\n",
      "Mobile optimization completed successfully!\n",
      "\n",
      "Testing optimized model...\n",
      "Test output shape: torch.Size([1, 67])\n",
      "Model successfully processes test input!\n"
     ]
    }
   ],
   "source": [
    "# # Load training results\n",
    "# print(\"Loading training results...\")\n",
    "# with open(\"logs/training_results.json\", 'r') as f:\n",
    "#     results = json.load(f)\n",
    "\n",
    "# print(f\"Loaded results - Best fold: {results['best_fold']}\")\n",
    "# print(f\"Best validation accuracy: {results['best_val_acc']}%\")\n",
    "\n",
    "# # Initialize model\n",
    "# model = IMUCNN(\n",
    "#     num_classes=results['num_classes'],\n",
    "#     window_length=results['window_length']\n",
    "# )\n",
    "\n",
    "# # Load best model weights\n",
    "# model_path = Path(\"models\") / f\"best_model_fold_{results['best_fold']}.pt\"\n",
    "# print(f\"Loading model from {model_path}\")\n",
    "# model.load_state_dict(torch.load(model_path, map_location='cpu', weights_only=True))\n",
    "\n",
    "# # Optimize for mobile\n",
    "# try:\n",
    "#     mobile_model = optimize_for_mobile(model, results)\n",
    "#     print(\"\\nMobile optimization completed successfully!\")\n",
    "    \n",
    "#     # Test the optimized model\n",
    "#     print(\"\\nTesting optimized model...\")\n",
    "#     test_input = torch.randn(1, 6, results['window_length'])\n",
    "#     with torch.no_grad():\n",
    "#         output = mobile_model(test_input)\n",
    "#         print(f\"Test output shape: {output.shape}\")\n",
    "#         print(\"Model successfully processes test input!\")\n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(f\"Error during mobile optimization: {str(e)}\")\n",
    "#     print(\"\\nDetailed error information:\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_f1.py\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from model import IMUCNN\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.data_processing import MemoryEfficientDataset, SignalPreprocessor\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"Evaluate model and get predictions\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training results...\n",
      "Loading dataset...\n",
      "Creating validation dataset for fold 0\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/3m5sc_792q1ccckrn_rdyfmh0000gn/T/ipykernel_98135/1897673065.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models/best_model_fold_0.pt\n",
      "\n",
      "Generating predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 949/949 [00:42<00:00, 22.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Scores:\n",
      "Macro F1: 0.9283\n",
      "Weighted F1: 0.9874\n",
      "\n",
      "Detailed Classification Report:\n",
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                     alternatingdumbbellcurl       0.00      0.00      0.00         3\n",
      "                           armbandadjustment       0.96      0.72      0.82        60\n",
      "                            bandpull-downrow       0.96      1.00      0.98        79\n",
      "                                 bicep_curls       0.97      1.00      0.99        39\n",
      "                                  bicepcurls       1.00      1.00      1.00       227\n",
      "                            bicepscurl(band)       1.00      0.99      0.99        86\n",
      "                                    boxjumps       1.00      1.00      1.00       619\n",
      "                                      burpee       1.00      1.00      1.00       309\n",
      "                                     burpees       1.00      1.00      1.00       677\n",
      "                             butterflysit-up       1.00      1.00      1.00       342\n",
      "                            chestpress(rack)       1.00      0.99      0.99        84\n",
      "                                      crunch       1.00      1.00      1.00       232\n",
      "                                    crunches       1.00      1.00      1.00       587\n",
      "                                   deadlifts       1.00      1.00      1.00       594\n",
      "                               deviceontable       1.00      1.00      1.00      4451\n",
      "                                         dip       1.00      0.98      0.99       168\n",
      "                               dumbbell_rows       1.00      1.00      1.00        34\n",
      "                     dumbbell_shoulder_press       1.00      1.00      1.00        75\n",
      "                                dumbbellrows       0.99      0.99      0.99       624\n",
      "                       dumbbellshoulderpress       1.00      1.00      1.00       425\n",
      "               dynamicstretch(atyourownpace)       0.96      0.96      0.96       748\n",
      "                           ellipticalmachine       1.00      1.00      1.00       543\n",
      "                      fastalternatingpunches       1.00      0.99      1.00       167\n",
      "                               jumping_jacks       0.00      0.00      0.00         2\n",
      "                                jumpingjacks       1.00      1.00      1.00        76\n",
      "                                    jumprope       1.00      1.00      1.00       256\n",
      "                                     kbpress       1.00      1.00      1.00       391\n",
      "                                kbsquatpress       1.00      1.00      1.00       431\n",
      "                             kettlebellswing       1.00      1.00      1.00       183\n",
      "                     lateral_shoulder_raises       1.00      1.00      1.00        85\n",
      "                       lateralshoulderraises       0.99      1.00      0.99       133\n",
      "                          lawnmower(leftarm)       0.99      1.00      0.99        86\n",
      "                         lawnmower(rightarm)       1.00      1.00      1.00        82\n",
      "                                      lunges       1.00      1.00      1.00       778\n",
      "                            medicineballslam       1.00      1.00      1.00        98\n",
      "                                       non-e       1.00      1.00      1.00      3398\n",
      "                                 nonexercise       0.83      0.92      0.88       306\n",
      "                                        note       1.00      0.87      0.93        23\n",
      "                                        null       0.99      0.98      0.99       269\n",
      "overheadtricepsextension(labelspansbotharms)       0.87      0.87      0.87        15\n",
      "                                       plank       0.99      0.98      0.99       350\n",
      "                               powerboatpose       0.98      0.99      0.99       153\n",
      "                                     pullups       1.00      1.00      1.00       269\n",
      "                                     pushups       1.00      1.00      1.00       719\n",
      "                        repetitivestretching       0.92      0.85      0.88       127\n",
      "                                        rest       0.95      0.96      0.95       379\n",
      "                               rowingmachine       1.00      1.00      1.00       613\n",
      "                          running(treadmill)       1.00      1.00      1.00       493\n",
      "                                russiantwist       0.99      0.97      0.98       238\n",
      "                               seatedbackfly       0.99      1.00      1.00       163\n",
      "                           sideplankleftside       0.99      0.96      0.97       140\n",
      "                          sideplankrightside       0.99      1.00      1.00       123\n",
      "           sit-up(handspositionedbehindhead)       0.99      1.00      1.00       248\n",
      "                                      situps       1.00      0.98      0.99       398\n",
      "                                      squats       1.00      0.99      0.99      1860\n",
      "                               staticstretch       0.96      0.95      0.95      1502\n",
      "                staticstretch(atyourownpace)       0.89      0.97      0.93      1014\n",
      "                               tapleftdevice       0.00      0.00      0.00         9\n",
      "                              taprightdevice       0.82      0.31      0.45        58\n",
      "                           tricep_extensions       0.98      1.00      0.99        51\n",
      "                            tricepextensions       0.99      0.98      0.99       706\n",
      "two-armdumbbellcurl(botharms,notalternating)       1.00      1.00      1.00       251\n",
      "                            unlistedexercise       1.00      0.69      0.82        13\n",
      "                                        v-up       1.00      1.00      1.00       235\n",
      "                                        walk       1.00      1.00      1.00      1866\n",
      "                                    wallball       1.00      0.99      0.99        88\n",
      "                                   wallballs       1.00      1.00      1.00       507\n",
      "\n",
      "                                    accuracy                           0.99     30358\n",
      "                                   macro avg       0.94      0.92      0.93     30358\n",
      "                                weighted avg       0.99      0.99      0.99     30358\n",
      "\n",
      "\n",
      "Metrics saved to logs/metrics_fold_0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/jackkrolik/.pyenv/versions/ds4440/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jackkrolik/.pyenv/versions/ds4440/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jackkrolik/.pyenv/versions/ds4440/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jackkrolik/.pyenv/versions/ds4440/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jackkrolik/.pyenv/versions/ds4440/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jackkrolik/.pyenv/versions/ds4440/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load training results\n",
    "print(\"Loading training results...\")\n",
    "with open(\"logs/training_results.json\", 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Load your data\n",
    "print(\"Loading dataset...\")\n",
    "data = pd.read_pickle('data/model_data_window_500_space_50.pkl')\n",
    "\n",
    "# Create indices for cross-validation (exactly as in training)\n",
    "indices = np.arange(len(data))\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Get the validation indices for the best fold\n",
    "best_fold = results['best_fold']\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(indices)):\n",
    "    if fold == best_fold:\n",
    "        break\n",
    "\n",
    "print(f\"Creating validation dataset for fold {best_fold}\")\n",
    "\n",
    "# Create validation dataset\n",
    "val_dataset = MemoryEfficientDataset(\n",
    "    data,\n",
    "    val_idx,\n",
    "    preprocessor=SignalPreprocessor(target_sampling_rate=50),\n",
    "    target_length=results['window_length']\n",
    ")\n",
    "\n",
    "# Create validation dataloader\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Initialize and load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = IMUCNN(\n",
    "    num_classes=results['num_classes'],\n",
    "    window_length=results['window_length']\n",
    ").to(device)\n",
    "\n",
    "model_path = Path(\"models\") / f\"best_model_fold_{best_fold}.pt\"\n",
    "print(f\"Loading model from {model_path}\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "predictions, labels = evaluate_model(model, val_loader, device)\n",
    "\n",
    "# Calculate metrics\n",
    "f1_macro = f1_score(labels, predictions, average='macro')\n",
    "f1_weighted = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "print(\"\\nF1 Scores:\")\n",
    "print(f\"Macro F1: {f1_macro:.4f}\")\n",
    "print(f\"Weighted F1: {f1_weighted:.4f}\")\n",
    "\n",
    "# Get class names from dataset\n",
    "class_names = val_dataset.label_encoder.classes_\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(labels, predictions, target_names=class_names))\n",
    "\n",
    "# Save results\n",
    "metrics = {\n",
    "    'f1_macro': float(f1_macro),\n",
    "    'f1_weighted': float(f1_weighted),\n",
    "    'classification_report': classification_report(labels, predictions, \n",
    "                                                target_names=class_names,\n",
    "                                                output_dict=True)\n",
    "}\n",
    "\n",
    "metrics_path = Path(\"logs\") / f\"metrics_fold_{best_fold}.json\"\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "print(f\"\\nMetrics saved to {metrics_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds4440",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
